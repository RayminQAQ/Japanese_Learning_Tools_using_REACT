{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Project Description: kuzushiji images classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Build: python 3.10\n",
    "\n",
    "2. Clone from: https://github.com/rois-codh/kmnist\n",
    "\n",
    "3. About the Kuzushiji-49 dataset used:\n",
    "\n",
    "   > Kuzushiji-49, as the name suggests, has 49 classes (28x28 grayscale, 270,912 images), is a much larger, but imbalanced dataset containing 48 Hiragana characters and one Hiragana iteration mark."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clone dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "you can run kuzushiji-49.py in terminal in order to download kuzushiji-49\n",
    "> python kuzushiji-49\n",
    "\n",
    "or you can download dataset by hand in:\n",
    "https://www.kaggle.com/datasets/anokas/kuzushiji"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Reference:\n",
    "1. https://stackoverflow.com/questions/18231135/load-compressed-data-npz-from-file-using-numpy-load\n",
    "2. source code demo from Kuzushiji-49 dataset\n",
    "\n",
    "Visualize Reference:\n",
    "1. https://blog.csdn.net/DarrenXf/article/details/120107983\n",
    "2. https://blog.csdn.net/qq_41554005/article/details/116093092"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (28, 28)\n",
      "[[  0   0   0   0   0   0   0   0   0   0  69 213  39  32 193  52   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0  58 235  65   0   0  64 222  15   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   8 213  59   0   0   0   9 229  93   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0  47 164   0   0   1  37  30 174  90   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0  77 132  28  84 172 252 239 199  10   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0  65 253 248 255 203 132  26 200 123  56\n",
      "   62  38   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   1 117 150  72   6   0   0 176 255 255\n",
      "  255 200   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 208 255 250\n",
      "  173  39   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0  15 150 246 132  48\n",
      "    1   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   1  28   0   8  92 230 254 247  39   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0  46 213 142 227 227 119  67 254  50   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0  61 212 244 176  33   0   9 244  63   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   7  17   1   0   0   1 220 109   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 188 127   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  28 190 128   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   3 126 253 254 118   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   4 185 255 255 255 203  16\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0  42 242 249 255 255 255 165\n",
      "    2   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0  99 235 246 255 179 178 253\n",
      "  115   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0  51 226 255 212  24  30 249\n",
      "  192   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0  32 157  38   0   0 197\n",
      "  229   2   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 170\n",
      "  242   6   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 197\n",
      "  188   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   6 231\n",
      "  129   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  39 254\n",
      "   50   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 115 216\n",
      "    6   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 196 104\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  55 246  36\n",
      "    0   0   0   0   0   0   0   0   0   0]] \n",
      " 30\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def load(f):\n",
    "    return np.load(f)['arr_0']\n",
    "\n",
    "train_data, train_label = load('kuzushiji-49/k49-train-imgs.npz'), load('kuzushiji-49/k49-train-labels.npz')\n",
    "test_data, test_label = load('kuzushiji-49/k49-test-imgs.npz'), load('kuzushiji-49/k49-test-labels.npz')\n",
    "\n",
    "# shape: (28, 28)\n",
    "print(f\"Shape: {train_data[0].shape}\")\n",
    "\n",
    "# data\n",
    "print(train_data[0], \"\\n\", train_label[0])\n",
    "\n",
    "del train_data, train_label, test_data, test_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualization\n",
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "train_data, train_label = load('kuzushiji-49/k49-train-imgs.npz'), load('kuzushiji-49/k49-train-labels.npz')\n",
    "test_data, test_label = load('kuzushiji-49/k49-test-imgs.npz'), load('kuzushiji-49/k49-test-labels.npz')\n",
    "DATA_CLASSMAP = './kuzushiji-49/k49_classmap.csv'\n",
    "\n",
    "def _search_classmap(id):\n",
    "    try:\n",
    "        with open(\"{}\".format(DATA_CLASSMAP), 'r', encoding='utf-8') as csvfile:\n",
    "            reader = csv.DictReader(csvfile)\n",
    "            for row in reader:\n",
    "                if str(id) == row['index']:\n",
    "                    return row['char']\n",
    "            return \"Not found\"\n",
    "        \n",
    "    except FileNotFoundError:\n",
    "        print(\"File is not open: check your DATA_CLASSMAP\")\n",
    "        return \"\"\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"ERROR: {e}\")\n",
    "        return \"\"\n",
    "        \n",
    "def visualization(index):\n",
    "    plt.imshow(train_data[index], interpolation='nearest')\n",
    "    plt.title('JP kuzushiji with id={}({})'.format(train_label[index], _search_classmap(train_label[index])), fontname=\"MS Gothic\")\n",
    "    plt.xticks([]) # 去掉刻度值\n",
    "    plt.yticks([])\n",
    "    plt.show()\n",
    "    \n",
    "visualization(0)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build model in pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reference:\n",
    "1. torch.nn.Module\n",
    "    - https://ithelp.ithome.com.tw/articles/10279986\n",
    "    \n",
    "2. torch.utils.data.Dataset && torch.utils.data.Dataloader\n",
    "    - https://rowantseng.medium.com/pytorch-%E8%87%AA%E5%AE%9A%E7%BE%A9%E8%B3%87%E6%96%99%E9%9B%86-custom-dataset-7f9958a8ff15\n",
    "    - https://blog.csdn.net/ljp1919/article/details/116484330\n",
    "    - https://pytorch.org/tutorials/beginner/basics/data_tutorial.html\n",
    "    - https://saturncloud.io/blog/converting-from-numpy-array-to-pytorch-tensor-a-comprehensive-guide/\n",
    "    - https://blog.csdn.net/weixin_41560402/article/details/108121344\n",
    "    \n",
    "3. Train && Test\n",
    "    - https://hackmd.io/@lido2370/SJMPbNnKN?type=view\n",
    "\n",
    "4. CNN theory recall\n",
    "    - https://blog.csdn.net/csdn_xmj/article/details/116206119\n",
    "    - https://blog.csdn.net/weixin_44912159/article/details/105345760"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KUZ_Model(\n",
      "  (network): Sequential(\n",
      "    (0): Conv2d(1, 3, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): Conv2d(3, 5, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (3): ReLU()\n",
      "    (4): Flatten(start_dim=1, end_dim=-1)\n",
      "    (5): Linear(in_features=2880, out_features=128, bias=True)\n",
      "    (6): ReLU()\n",
      "    (7): Linear(in_features=128, out_features=50, bias=True)\n",
      "    (8): Softmax(dim=None)\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nfrom torchinfo import summary\\nsummary(KUZ_Model, input_size=[28,28])\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "# IMG_Channel, IMG_ROWS, IMG_COLS = 1, 28, 28\n",
    "\n",
    "class KUZ_Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(KUZ_Model, self).__init__()\n",
    "        \n",
    "        self.network = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=1, out_channels=3, kernel_size=3, stride=1), # output shape 3 * (28-2) * (28-2)\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=3, out_channels=5, kernel_size=3, stride=1), # output shape 5 * (28-2-2) * (28-2-2)\n",
    "            nn.ReLU(),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(5*24*24, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 50),\n",
    "            nn.Softmax()\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.network(x)\n",
    "    \n",
    "print(KUZ_Model())\n",
    "\n",
    "\"\"\"\n",
    "from torchinfo import summary\n",
    "summary(KUZ_Model, input_size=[28,28])\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data.dataset import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "def load(f):\n",
    "    return np.load(f)['arr_0']\n",
    "\n",
    "class KUZ49_Dataset(Dataset):\n",
    "    def __init__(self, DATA_DIR_ROOT, split, transform):\n",
    "        # --------------------------------------------\n",
    "        # Initialize paths, transforms, and so on\n",
    "        # --------------------------------------------\n",
    "        self.transform = transform\n",
    "        \n",
    "        if split != \"test\" and split != \"train\":\n",
    "            print(\"SYNTAX ERROR WHILE LOADING KUZ49_Dataset\")\n",
    "            \n",
    "        self.imgs = load(f'{DATA_DIR_ROOT}/k49-{split}-imgs.npz')     \n",
    "        self.img_labels = load(f'{DATA_DIR_ROOT}/k49-{split}-labels.npz')\n",
    "        \n",
    "    def __getitem__(self, index) -> tuple[torch.Tensor, int]:\n",
    "        # --------------------------------------------\n",
    "        # 1. Read from file (using numpy.fromfile, PIL.Image.open)\n",
    "        # 2. Preprocess the data (torchvision.Transform).\n",
    "        # 3. Return the data (e.g. image and label)\n",
    "        # --------------------------------------------\n",
    "        image, label = self.imgs[index], self.img_labels[index]\n",
    "        \n",
    "        if self.transform is not None:\n",
    "            image = self.transform(image)\n",
    "            label = self.transform(label)\n",
    "        else:\n",
    "            image = torch.from_numpy(image).type(torch.LongTensor)\n",
    "            label = torch.from_numpy(label).type(torch.LongTensor)\n",
    "        \n",
    "        return image, label\n",
    "        \n",
    "    def __len__(self) -> int:\n",
    "        # --------------------------------------------\n",
    "        # Indicate the total size of the dataset\n",
    "        # -------------------------------------------\n",
    "        return len(self.imgs)\n",
    "    \n",
    "    def _imageShape(self):\n",
    "        return self.imgs.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.8171,  0.3016,  0.2358,  1.4716],\n",
      "        [ 0.6366,  1.1958, -0.0111, -1.0026]])\n",
      "tensor([1.4716, 1.1958])\n",
      "tensor([3, 1])\n"
     ]
    }
   ],
   "source": [
    "# TEST AREA: torch.tensor\n",
    "import torch\n",
    "\n",
    "tensor1 = torch.tensor([1,2,3,4])\n",
    "tensor2 = torch.randn(2, 4)\n",
    "print(tensor2)\n",
    "\n",
    "print(torch.max(tensor2, 1)[0])\n",
    "print(torch.max(tensor2, 1)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Web_related\\Japanese_Learning_Tools_using_REACT\\model\\venv-python310-data\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "def _trainstep(model: torch.nn.Module, \n",
    "              train_loader: torch.utils.data.DataLoader, \n",
    "              loss_func: torch.nn.Module, \n",
    "              optimizer: torch.optim.Optimizer):\n",
    "\n",
    "    train_loss, train_acc = 0, 0 \n",
    "    \n",
    "    model.train()\n",
    "    for batch, (images, labels) in enumerate(train_loader):\n",
    "        # Get Loss\n",
    "        outputs = model(images)\n",
    "        loss = loss_func(outputs, labels)\n",
    "        train_loss += loss.item()\n",
    "        \n",
    "        # Compute && Update Gradient\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Calculate and accumulate accuracy metric across all batches\n",
    "        predict_Seq = torch.max(outputs, 1)[1]\n",
    "        train_acc += ((predict_Seq==labels).sum().item()/len(outputs))\n",
    "        \n",
    "    train_loss = train_loss / len(train_loader)\n",
    "    train_acc = train_acc / len(train_loader)\n",
    "    return train_loss, train_acc\n",
    "\n",
    "def _teststep(model: torch.nn.Module, \n",
    "              test_loader: torch.utils.data.DataLoader, \n",
    "              loss_func: torch.nn.Module):\n",
    "    \n",
    "    test_loss, test_acc = 0, 0\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for batch, (images, labels) in enumerate(test_loader):\n",
    "            # Get Loss\n",
    "            outputs = model(images)\n",
    "            loss = loss_func(outputs, labels)\n",
    "            test_loss += loss.item()\n",
    "             \n",
    "            # Calculate and accumulate accuracy metric across all batches\n",
    "            predict_Seq = torch.max(outputs, 1)[1]\n",
    "            test_acc += ((predict_Seq==labels).sum().item()/len(outputs))\n",
    "            \n",
    "def fit_model(model: torch.nn.Module, \n",
    "              train_loader: torch.utils.data.DataLoader, \n",
    "              test_loader: torch.utils.data.DataLoader,\n",
    "              loss_func: torch.nn.Module, \n",
    "              optimizer: torch.optim.Optimizer,\n",
    "              input_shape: any, num_epochs: int):\n",
    "    \n",
    "    results = {\n",
    "        \"train_loss\": [], \n",
    "        \"train_acc\": [], \n",
    "        \"test_loss\": [], \n",
    "        \"test_acc\": []\n",
    "    }\n",
    "    \n",
    "    for epoch in tqdm(range(num_epochs)):\n",
    "        train_loss, train_acc = _trainstep(model, train_loader, loss_func, optimizer)            \n",
    "        test_loss, test_acc = _teststep(model, test_loader, loss_func) \n",
    "        \n",
    "        # print\n",
    "        print(\n",
    "            f\"Epoch: {epoch+1} | \"\n",
    "            f\"train_loss: {train_loss:.4f} | \"\n",
    "            f\"train_acc: {train_acc:.4f} | \"\n",
    "            f\"test_loss: {test_loss:.4f} | \"\n",
    "            f\"test_acc: {test_acc:.4f}\"\n",
    "        )\n",
    "        \n",
    "        # Note: The results obtained correspond to each epoch's performance metrics.\n",
    "        results[\"train_loss\"].append(train_loss)\n",
    "        results[\"train_acc\"].append(train_acc) \n",
    "        results[\"test_loss\"].append(test_loss) \n",
    "        results[\"test_acc\"].append(test_acc) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Hyper Parameters\n",
    "LR = 0.01\n",
    "batch_size = 32\n",
    "num_epochs = 1\n",
    "\n",
    "# Pytorch DataLoader\n",
    "train_loader = DataLoader(KUZ49_Dataset(DATA_DIR_ROOT='kuzushiji-49', split='train', transform=None), batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "test_loader = DataLoader(KUZ49_Dataset(DATA_DIR_ROOT='kuzushiji-49', split='test', transform=None), batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "\n",
    "# \n",
    "model = KUZ_Model()\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LR)   # optimize all cnn parameters\n",
    "loss_func = nn.CrossEntropyLoss()   # the target label is not one-hotted\n",
    "input_shape = (1,28,28)\n",
    "\n",
    "fit_model(model, train_loader, test_loader, loss_func, optimizer, input_shape, num_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, 'save.pt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv-python310-data",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
